{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from qdrant_client import QdrantClient\n",
    "from cache.cache import Cache\n",
    "\n",
    "\n",
    "qdrant_client = QdrantClient(host=\"localhost\", port=6333)\n",
    "es_client = Elasticsearch(\n",
    "    hosts=[\"http://localhost:9200\"],\n",
    ")\n",
    "cache = Cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll run tests, but not for every possible combination.\n",
    "We want to focus more on the differences between the worst and the best models we have.\n",
    "We'll select few models, starting with the worst to the best.\n",
    "\n",
    "Combinations for poquad dataset\n",
    "Best one - morfologik_index-intfloat/multilingual-e5-large-Cosine-clarin-pl-poquad-100000-0.5-sdadas/polish-reranker-large-ranknet\n",
    "\n",
    "50 percentile - BAAI/bge-m3-Euclid-clarin-pl-poquad-500\n",
    "\n",
    "Worst one - basic_index-clarin-pl-poquad-500\n",
    "\n",
    "Combinations for polqa dataset\n",
    "Best one - morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.05\n",
    "\n",
    "50 percentile - sdadas/mmlw-roberta-large-Cosine-ipipan-polqa-2000\n",
    "\n",
    "Worst one - basic_index-ipipan-polqa-500-sdadas/polish-reranker-large-ranknet\n",
    "\n",
    "\n",
    "Each dataset will be run with 2 QA models and 2 Instruction models\n",
    "\n",
    "To run tests faster we'll select smaller batches of questions. Probably 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.names import  OPENAI_EMBEDDING_MODEL_NAMES, PASSAGE_PREFIX_MAP, QUERY_PREFIX_MAP\n",
    "from repository.es_repository import ESRepository\n",
    "from repository.qdrant_openai_repository import QdrantOpenAIRepository\n",
    "from repository.qdrant_repository import QdrantRepository\n",
    "from qdrant_client.models import Distance\n",
    "\n",
    "from rerankers.hf_reranker import HFReranker\n",
    "from retrievers.es_retriever import ESRetriever\n",
    "from retrievers.hybrid_retriever import HybridRetriever\n",
    "from retrievers.qdrant_retriever import QdrantRetriever\n",
    "from retrievers.retriever import Retriever\n",
    "\n",
    "\n",
    "def get_best_poquad_retriever() -> tuple[Retriever, str]:\n",
    "    dataset_key = \"clarin-pl-poquad-100000\"\n",
    "    es_index = \"morfologik_index\"\n",
    "    qdrant_model = \"intfloat/multilingual-e5-large\"\n",
    "    reranker_model = \"sdadas/polish-reranker-large-ranknet\"\n",
    "    alpha = 0.5\n",
    "\n",
    "    es_repository = ESRepository(es_client, es_index, cache)\n",
    "    passage_prefix = PASSAGE_PREFIX_MAP[qdrant_model]\n",
    "    query_prefix = QUERY_PREFIX_MAP[qdrant_model]\n",
    "    qdrant_repository = QdrantRepository.get_repository(\n",
    "        qdrant_client,\n",
    "        qdrant_model,\n",
    "        Distance.COSINE,\n",
    "        cache,\n",
    "        passage_prefix,\n",
    "        query_prefix,\n",
    "    )\n",
    "    reranker = HFReranker(reranker_model, cache)\n",
    "\n",
    "    retriever = HybridRetriever(\n",
    "        es_repository, qdrant_repository, dataset_key, alpha, reranker\n",
    "    )\n",
    "\n",
    "    return (retriever, \"morfologik_index-intfloat/multilingual-e5-large-Cosine-clarin-pl-poquad-100000-0.5-sdadas/polish-reranker-large-ranknet\")\n",
    "\n",
    "\n",
    "def get_50p_poquad_retriever() -> tuple[Retriever, str]:\n",
    "    dataset_key = \"clarin-pl-poquad-1000\"\n",
    "    qdrant_model = \"sdadas/mmlw-retrieval-roberta-large\"\n",
    "\n",
    "    passage_prefix = PASSAGE_PREFIX_MAP[qdrant_model]\n",
    "    query_prefix = QUERY_PREFIX_MAP[qdrant_model]\n",
    "    qdrant_repository = QdrantRepository.get_repository(\n",
    "        qdrant_client,\n",
    "        qdrant_model,\n",
    "        Distance.EUCLID,\n",
    "        cache,\n",
    "        passage_prefix,\n",
    "        query_prefix,\n",
    "    )\n",
    "\n",
    "    retriever = QdrantRetriever(qdrant_repository, dataset_key)\n",
    "\n",
    "    return (\n",
    "        retriever,\n",
    "        \"sdadas/mmlw-retrieval-roberta-large-Euclid-clarin-pl-poquad-1000\",\n",
    "    )\n",
    "\n",
    "\n",
    "def get_worst_poquad_retriever() -> tuple[Retriever, str]:\n",
    "    dataset_key = \"clarin-pl-poquad-500\"\n",
    "    es_index = \"basic_index\"\n",
    "\n",
    "    es_repository = ESRepository(es_client, es_index, cache)\n",
    "\n",
    "    retriever = ESRetriever(es_repository, dataset_key)\n",
    "\n",
    "    return (retriever, \"basic_index-clarin-pl-poquad-500\")\n",
    "\n",
    "\n",
    "def get_best_poquad_openai_retriever() -> tuple[Retriever, str]:\n",
    "    repository = QdrantOpenAIRepository.get_repository(\n",
    "        qdrant_client, OPENAI_EMBEDDING_MODEL_NAMES[0], Distance.COSINE, cache\n",
    "    )\n",
    "\n",
    "    retriever = QdrantRetriever(repository, \"clarin-pl-poquad-2000\")\n",
    "\n",
    "    return (retriever, \"text-embedding-3-large-Cosine-clarin-pl-poquad-2000\")\n",
    "\n",
    "\n",
    "def get_worst_poquad_openai_retriever() -> tuple[Retriever, str]:\n",
    "    repository = QdrantOpenAIRepository.get_repository(\n",
    "        qdrant_client, OPENAI_EMBEDDING_MODEL_NAMES[0], Distance.COSINE, cache\n",
    "    )\n",
    "\n",
    "    retriever = QdrantRetriever(repository, \"clarin-pl-poquad-500\")\n",
    "\n",
    "    return (retriever, \"text-embedding-3-large-Cosine-clarin-pl-poquad-500\")\n",
    "\n",
    "\n",
    "def get_best_polqa_retriever() -> tuple[Retriever, str]:\n",
    "    dataset_key = \"ipipan-polqa-1000\"\n",
    "    es_index = \"morfologik_index\"\n",
    "    qdrant_model = \"sdadas/mmlw-retrieval-roberta-large\"\n",
    "    reranker_model = \"sdadas/polish-reranker-large-ranknet\"\n",
    "    alpha = 0.75\n",
    "\n",
    "    es_repository = ESRepository(es_client, es_index, cache)\n",
    "    passage_prefix = PASSAGE_PREFIX_MAP[qdrant_model]\n",
    "    query_prefix = QUERY_PREFIX_MAP[qdrant_model]\n",
    "    qdrant_repository = QdrantRepository.get_repository(\n",
    "        qdrant_client,\n",
    "        qdrant_model,\n",
    "        Distance.COSINE,\n",
    "        cache,\n",
    "        passage_prefix,\n",
    "        query_prefix,\n",
    "    )\n",
    "    reranker = HFReranker(reranker_model, cache)\n",
    "\n",
    "    retriever = HybridRetriever(\n",
    "        es_repository, qdrant_repository, dataset_key, alpha, reranker\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        retriever,\n",
    "        \"morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.5-sdadas/polish-reranker-large-ranknet\",\n",
    "    )\n",
    "\n",
    "\n",
    "def get_50p_polqa_retriever() -> tuple[Retriever, str]:\n",
    "    dataset_key = \"ipipan-polqa-1000\"\n",
    "    es_index = \"morfologik_index\"\n",
    "    qdrant_model = \"sdadas/mmlw-retrieval-roberta-large\"\n",
    "    alpha = 0.75\n",
    "\n",
    "    es_repository = ESRepository(es_client, es_index, cache)\n",
    "    passage_prefix = PASSAGE_PREFIX_MAP[qdrant_model]\n",
    "    query_prefix = QUERY_PREFIX_MAP[qdrant_model]\n",
    "    qdrant_repository = QdrantRepository.get_repository(\n",
    "        qdrant_client,\n",
    "        qdrant_model,\n",
    "        Distance.COSINE,\n",
    "        cache,\n",
    "        passage_prefix,\n",
    "        query_prefix,\n",
    "    )\n",
    "\n",
    "    retriever = HybridRetriever(\n",
    "        es_repository, qdrant_repository, dataset_key, alpha\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        retriever,\n",
    "        \"morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.75\",\n",
    "    )\n",
    "\n",
    "\n",
    "def get_worst_polqa_retriever() -> tuple[Retriever, str]:\n",
    "    dataset_key = \"ipipan-polqa-500\"\n",
    "    es_index = \"basic_index\"\n",
    "\n",
    "    es_repository = ESRepository(es_client, es_index, cache)\n",
    "\n",
    "    retriever = ESRetriever(\n",
    "        es_repository, dataset_key\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        retriever,\n",
    "        \"basic_index-ipipan-polqa-500\",\n",
    "    )\n",
    "\n",
    "\n",
    "def get_best_polqa_openai_retriever() -> tuple[Retriever, str]:\n",
    "    repository = QdrantOpenAIRepository.get_repository(\n",
    "        qdrant_client, OPENAI_EMBEDDING_MODEL_NAMES[0], Distance.EUCLID, cache\n",
    "    )\n",
    "\n",
    "    retriever = QdrantRetriever(repository, \"ipipan-polqa-2000\")\n",
    "\n",
    "    return (retriever, \"text-embedding-3-large-Euclid-ipipan-polqa-2000\")\n",
    "\n",
    "\n",
    "def get_worst_polqa_openai_retriever() -> tuple[Retriever, str]:\n",
    "    repository = QdrantOpenAIRepository.get_repository(\n",
    "        qdrant_client, OPENAI_EMBEDDING_MODEL_NAMES[0], Distance.COSINE, cache\n",
    "    )\n",
    "\n",
    "    retriever = QdrantRetriever(repository, \"ipipan-polqa-500\")\n",
    "\n",
    "    return (retriever, \"text-embedding-3-large-Cosine-ipipan-polqa-500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "poquad_retriever_functions = [\n",
    "    get_best_poquad_retriever,\n",
    "    get_50p_poquad_retriever,\n",
    "    get_worst_poquad_retriever,\n",
    "]\n",
    "\n",
    "poquad_openai_retriever_functions = [\n",
    "    get_best_poquad_openai_retriever,\n",
    "    get_worst_poquad_openai_retriever,\n",
    "]\n",
    "\n",
    "polqa_retriever_functions = [\n",
    "    get_best_polqa_retriever,\n",
    "    get_50p_polqa_retriever,\n",
    "    get_worst_polqa_retriever,\n",
    "]\n",
    "\n",
    "polqa_openai_retriever_functions = [\n",
    "    get_best_polqa_openai_retriever,\n",
    "    get_worst_polqa_openai_retriever,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.names import DATASET_SEED\n",
    "from dataset.polqa_dataset_getter import PolqaDatasetGetter\n",
    "from dataset.poquad_dataset_getter import PoquadDatasetGetter\n",
    "\n",
    "\n",
    "poquad_dataset_getter = PoquadDatasetGetter()\n",
    "polqa_dataset_getter = PolqaDatasetGetter()\n",
    "\n",
    "poquad_dataset = poquad_dataset_getter.get_random_n_test(500, DATASET_SEED)[:100]\n",
    "polqa_dataset = polqa_dataset_getter.get_random_n_test(500, DATASET_SEED)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [1, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import Dict\n",
    "from common.dataset_entry import DatasetEntry\n",
    "from evaluation.qa_evaluator import QAEvaluator\n",
    "from generators.generator import Generator\n",
    "\n",
    "qa_evaluator = QAEvaluator()\n",
    "\n",
    "\n",
    "def run_qa_evaluation(retriever: Retriever, generator: Generator, dataset: list[DatasetEntry], name, generator_name, n):\n",
    "    scores: Dict[str, float] = {}\n",
    "\n",
    "    em = []\n",
    "    f1 = []\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for entry in dataset:\n",
    "        if i  % 10 == 0:\n",
    "            print(f\"Processing {i} out of {len(dataset)}\")\n",
    "\n",
    "        question = entry.question\n",
    "        correct_answers = entry.answers\n",
    "\n",
    "        retriever_result = retriever.get_relevant_passages(question)\n",
    "        passages = [passage for (passage, _) in retriever_result.passages]\n",
    "        top_n_passages = passages[:n]\n",
    "\n",
    "        answer = generator.generate_answer(question, top_n_passages)\n",
    "\n",
    "        exact_match_score = qa_evaluator.calculate_em(answer, correct_answers)\n",
    "        f1_score = qa_evaluator.calculate_f1_score(answer, correct_answers)\n",
    "\n",
    "        em.append(exact_match_score)\n",
    "        f1.append(f1_score)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    scores[\"em\"] = sum(em) / len(em)\n",
    "    scores[\"f1\"] = sum(f1) / len(f1)\n",
    "\n",
    "    print(f\"name: {name}, generator: {generator_name}, n: {n}, em: {scores['em']}, f1: {scores['f1']}\")\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.hallucination_evaluator import HallucinationEvaluator\n",
    "\n",
    "\n",
    "def run_instruction_evaluation(retriever: Retriever, generator: Generator, dataset: list[DatasetEntry], name, generator_name, n):\n",
    "    # hallucination_evaluator = HallucinationEvaluator(cache)\n",
    "\n",
    "    scores: Dict[str, float] = {}\n",
    "\n",
    "    confidence_score = []\n",
    "    above = 0\n",
    "    below = 0\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for entry in dataset:\n",
    "        if i  % 10 == 0:\n",
    "            print(f\"Processing {i} out of {len(dataset)}\")\n",
    "\n",
    "        question = entry.question\n",
    "\n",
    "        retriever_result = retriever.get_relevant_passages(question)\n",
    "        passages = [passage for (passage, _) in retriever_result.passages]\n",
    "        top_n_passages = passages[:n]\n",
    "\n",
    "        answer = generator.generate_answer(question, top_n_passages)\n",
    "\n",
    "        # score = hallucination_evaluator.calculate(question, answer, top_n_passages)\n",
    "        score = 0.0\n",
    "\n",
    "        confidence_score.append(score)\n",
    "        if score >= 0.5:\n",
    "            above += 1\n",
    "        else:\n",
    "            below += 1\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    scores[\"confidence\"] = sum(confidence_score) / len(confidence_score)\n",
    "    scores[\"above\"] = above\n",
    "    scores[\"below\"] = below\n",
    "\n",
    "    print(f\"name: {name}, generator: {generator_name}, n: {n}, confidence: {scores['confidence']}, above: {scores['above']}, below: {scores['below']}\")\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import Dict\n",
    "\n",
    "from common.names import INST_MODEL_PATHS, QA_MODEL_NAMES\n",
    "from generators.instruction_generator import InstructionGenerator\n",
    "from generators.openai_generator import OpenAIGenerator\n",
    "from generators.question_answering_generator import QuestionAnsweringGenerator\n",
    "\n",
    "\n",
    "def run_poquad_evaluations():\n",
    "    poquad_scores: Dict[str, float] = {}\n",
    "\n",
    "    for retriever_func in poquad_retriever_functions:\n",
    "        (retriever, name) = retriever_func()\n",
    "\n",
    "        for n in ns:\n",
    "            for qa_model_name in QA_MODEL_NAMES:\n",
    "                generator = QuestionAnsweringGenerator(qa_model_name, cache)\n",
    "                scores = run_qa_evaluation(\n",
    "                    retriever, generator, poquad_dataset, name, qa_model_name, n\n",
    "                )\n",
    "                poquad_scores[f\"{name}-QA-{qa_model_name}-{n}\"] = scores\n",
    "\n",
    "            for instruction_models in INST_MODEL_PATHS:\n",
    "                generator = InstructionGenerator(instruction_models, cache)\n",
    "\n",
    "                scores = run_instruction_evaluation(\n",
    "                    retriever, generator, poquad_dataset, name, instruction_models, n\n",
    "                )\n",
    "\n",
    "                poquad_scores[f\"{name}-INST-{instruction_models}-{n}\"] = scores\n",
    "\n",
    "    for retriever_func in poquad_openai_retriever_functions:\n",
    "        (retriever, name) = retriever_func()\n",
    "\n",
    "        for n in ns:\n",
    "            generator = OpenAIGenerator(cache)\n",
    "            scores = run_instruction_evaluation(\n",
    "                retriever, generator, poquad_dataset, name, \"gpt-4o-mini\", n\n",
    "            )\n",
    "            poquad_scores[f\"{name}-QA-gpt-4o-mini-{n}\"] = scores\n",
    "\n",
    "    return poquad_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_polqa_evaluations():\n",
    "    polqa_scores: Dict[str, float] = {}\n",
    "\n",
    "    for retriever_func in polqa_retriever_functions:\n",
    "        (retriever, name) = retriever_func()\n",
    "\n",
    "        for n in ns:\n",
    "            for qa_model_name in QA_MODEL_NAMES:\n",
    "                generator = QuestionAnsweringGenerator(qa_model_name, cache)\n",
    "                scores = run_qa_evaluation(retriever, generator, polqa_dataset, name, qa_model_name, n)\n",
    "                polqa_scores[f\"{name}-QA-{qa_model_name}-{n}\"] = scores\n",
    "\n",
    "            for instruction_models in INST_MODEL_PATHS:\n",
    "                generator = InstructionGenerator(instruction_models, cache)\n",
    "\n",
    "                scores = run_instruction_evaluation(\n",
    "                    retriever, generator, polqa_dataset, name, instruction_models, n\n",
    "                )\n",
    "\n",
    "                polqa_scores[f\"{name}-INST-{instruction_models}-{n}\"] = scores\n",
    "\n",
    "    for retriever_func in polqa_openai_retriever_functions:\n",
    "        (retriever, name) = retriever_func()\n",
    "\n",
    "        for n in ns:\n",
    "            generator = OpenAIGenerator(cache)\n",
    "            scores = run_instruction_evaluation(\n",
    "                retriever, generator, polqa_dataset, name, \"gpt-4o-mini\", n\n",
    "            )\n",
    "            polqa_scores[f\"{name}-QA-gpt-4o-mini-{n}\"] = scores\n",
    "\n",
    "    return polqa_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer with model sdadas/mmlw-retrieval-roberta-large initialized\n",
      "Qdrant collection sdadas-mmlw-retrieval-roberta-large-Cosine repository initialized\n",
      "Vectorizer with model sdadas/polish-reranker-large-ranknet initialized\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.5-sdadas/polish-reranker-large-ranknet, generator: radlab/polish-qa-v2, n: 1, em: 0.28, f1: 0.41923809523809524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jakubkusiowski/Desktop/Workspace/polish-nl-qa/env/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.5-sdadas/polish-reranker-large-ranknet, generator: timpal0l/mdeberta-v3-base-squad2, n: 1, em: 0.24, f1: 0.40114285714285713\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.5-sdadas/polish-reranker-large-ranknet, generator: ../../models/Bielik-11B-v2.2-Instruct-q4, n: 1, confidence: 0.0, above: 0, below: 100\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.5-sdadas/polish-reranker-large-ranknet, generator: ../../models/Mistral-7B-Instruct-v0.2-q4, n: 1, confidence: 0.0, above: 0, below: 100\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.5-sdadas/polish-reranker-large-ranknet, generator: radlab/polish-qa-v2, n: 5, em: 0.25, f1: 0.3872380952380952\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.5-sdadas/polish-reranker-large-ranknet, generator: timpal0l/mdeberta-v3-base-squad2, n: 5, em: 0.27, f1: 0.41733333333333333\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.5-sdadas/polish-reranker-large-ranknet, generator: ../../models/Bielik-11B-v2.2-Instruct-q4, n: 5, confidence: 0.0, above: 0, below: 100\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.5-sdadas/polish-reranker-large-ranknet, generator: ../../models/Mistral-7B-Instruct-v0.2-q4, n: 5, confidence: 0.0, above: 0, below: 100\n",
      "Vectorizer with model sdadas/mmlw-retrieval-roberta-large initialized\n",
      "Qdrant collection sdadas-mmlw-retrieval-roberta-large-Cosine repository initialized\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.75, generator: radlab/polish-qa-v2, n: 1, em: 0.27, f1: 0.40423809523809523\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.75, generator: timpal0l/mdeberta-v3-base-squad2, n: 1, em: 0.23, f1: 0.3928095238095238\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.75, generator: ../../models/Bielik-11B-v2.2-Instruct-q4, n: 1, confidence: 0.0, above: 0, below: 100\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.75, generator: ../../models/Mistral-7B-Instruct-v0.2-q4, n: 1, confidence: 0.0, above: 0, below: 100\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.75, generator: radlab/polish-qa-v2, n: 5, em: 0.29, f1: 0.42923809523809525\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.75, generator: timpal0l/mdeberta-v3-base-squad2, n: 5, em: 0.25, f1: 0.3874761904761905\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.75, generator: ../../models/Bielik-11B-v2.2-Instruct-q4, n: 5, confidence: 0.0, above: 0, below: 100\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.75, generator: ../../models/Mistral-7B-Instruct-v0.2-q4, n: 5, confidence: 0.0, above: 0, below: 100\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: basic_index-ipipan-polqa-500, generator: radlab/polish-qa-v2, n: 1, em: 0.21, f1: 0.31923809523809527\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: basic_index-ipipan-polqa-500, generator: timpal0l/mdeberta-v3-base-squad2, n: 1, em: 0.16, f1: 0.2948095238095238\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: basic_index-ipipan-polqa-500, generator: ../../models/Bielik-11B-v2.2-Instruct-q4, n: 1, confidence: 0.0, above: 0, below: 100\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: basic_index-ipipan-polqa-500, generator: ../../models/Mistral-7B-Instruct-v0.2-q4, n: 1, confidence: 0.0, above: 0, below: 100\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: basic_index-ipipan-polqa-500, generator: radlab/polish-qa-v2, n: 5, em: 0.22, f1: 0.3437765567765567\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: basic_index-ipipan-polqa-500, generator: timpal0l/mdeberta-v3-base-squad2, n: 5, em: 0.2, f1: 0.3332943722943723\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: basic_index-ipipan-polqa-500, generator: ../../models/Bielik-11B-v2.2-Instruct-q4, n: 5, confidence: 0.0, above: 0, below: 100\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: basic_index-ipipan-polqa-500, generator: ../../models/Mistral-7B-Instruct-v0.2-q4, n: 5, confidence: 0.0, above: 0, below: 100\n",
      "Vectorizer with model text-embedding-3-large initialized\n",
      "Qdrant openai collection text-embedding-3-large-Euclid repository initialized\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: text-embedding-3-large-Euclid-ipipan-polqa-2000, generator: gpt-4o-mini, n: 1, confidence: 0.0, above: 0, below: 100\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: text-embedding-3-large-Euclid-ipipan-polqa-2000, generator: gpt-4o-mini, n: 5, confidence: 0.0, above: 0, below: 100\n",
      "Vectorizer with model text-embedding-3-large initialized\n",
      "Qdrant openai collection text-embedding-3-large-Cosine repository initialized\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: text-embedding-3-large-Cosine-ipipan-polqa-500, generator: gpt-4o-mini, n: 1, confidence: 0.0, above: 0, below: 100\n",
      "Processing 0 out of 100\n",
      "Processing 10 out of 100\n",
      "Processing 20 out of 100\n",
      "Processing 30 out of 100\n",
      "Processing 40 out of 100\n",
      "Processing 50 out of 100\n",
      "Processing 60 out of 100\n",
      "Processing 70 out of 100\n",
      "Processing 80 out of 100\n",
      "Processing 90 out of 100\n",
      "name: text-embedding-3-large-Cosine-ipipan-polqa-500, generator: gpt-4o-mini, n: 5, confidence: 0.0, above: 0, below: 100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "polqa_scores = None\n",
    "cached_polqa_scores = cache.get(\"score:generator_polqa\")\n",
    "\n",
    "if cached_polqa_scores is not None:\n",
    "    polqa_scores = json.loads(cached_polqa_scores)\n",
    "else:\n",
    "    polqa_scores = run_polqa_evaluations()\n",
    "    cache.set(\"score:generator_polqa\", json.dumps(polqa_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "poquad_scores = None\n",
    "cached_poquad_scores = cache.get(\"score:generator_poquad\")\n",
    "\n",
    "if cached_poquad_scores is not None:\n",
    "    poquad_scores = json.loads(cached_poquad_scores)\n",
    "else:\n",
    "    poquad_scores = run_poquad_evaluations()\n",
    "    cache.set(\"score:generator_poquad\", json.dumps(poquad_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results as csv\n",
    "import csv\n",
    "\n",
    "\n",
    "def save_scores_to_csv(scores, filename):\n",
    "    with open(filename, mode=\"w\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"model\", \"em\", \"f1\"])\n",
    "        \n",
    "        for key, value in scores.items():\n",
    "            print(key, value)\n",
    "            if \"em\" in value and \"f1\" in value:            \n",
    "                writer.writerow(\n",
    "                    [\n",
    "                        key,\n",
    "                        str(value[\"em\"]).replace(\".\", \",\"),\n",
    "                        str(value[\"f1\"]).replace(\".\", \",\"),\n",
    "                    ]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.5-sdadas/polish-reranker-large-ranknet-QA-radlab/polish-qa-v2-1 {'em': 0.28, 'f1': 0.41923809523809524}\n",
      "morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.5-sdadas/polish-reranker-large-ranknet-QA-timpal0l/mdeberta-v3-base-squad2-1 {'em': 0.24, 'f1': 0.40114285714285713}\n",
      "morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.5-sdadas/polish-reranker-large-ranknet-INST-../../models/Bielik-11B-v2.2-Instruct-q4-1 {'confidence': 0.0, 'above': 0, 'below': 100}\n",
      "morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.5-sdadas/polish-reranker-large-ranknet-INST-../../models/Mistral-7B-Instruct-v0.2-q4-1 {'confidence': 0.0, 'above': 0, 'below': 100}\n",
      "morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.5-sdadas/polish-reranker-large-ranknet-QA-radlab/polish-qa-v2-5 {'em': 0.25, 'f1': 0.3872380952380952}\n",
      "morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.5-sdadas/polish-reranker-large-ranknet-QA-timpal0l/mdeberta-v3-base-squad2-5 {'em': 0.27, 'f1': 0.41733333333333333}\n",
      "morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.5-sdadas/polish-reranker-large-ranknet-INST-../../models/Bielik-11B-v2.2-Instruct-q4-5 {'confidence': 0.0, 'above': 0, 'below': 100}\n",
      "morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.5-sdadas/polish-reranker-large-ranknet-INST-../../models/Mistral-7B-Instruct-v0.2-q4-5 {'confidence': 0.0, 'above': 0, 'below': 100}\n",
      "morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.75-QA-radlab/polish-qa-v2-1 {'em': 0.27, 'f1': 0.40423809523809523}\n",
      "morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.75-QA-timpal0l/mdeberta-v3-base-squad2-1 {'em': 0.23, 'f1': 0.3928095238095238}\n",
      "morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.75-INST-../../models/Bielik-11B-v2.2-Instruct-q4-1 {'confidence': 0.0, 'above': 0, 'below': 100}\n",
      "morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.75-INST-../../models/Mistral-7B-Instruct-v0.2-q4-1 {'confidence': 0.0, 'above': 0, 'below': 100}\n",
      "morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.75-QA-radlab/polish-qa-v2-5 {'em': 0.29, 'f1': 0.42923809523809525}\n",
      "morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.75-QA-timpal0l/mdeberta-v3-base-squad2-5 {'em': 0.25, 'f1': 0.3874761904761905}\n",
      "morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.75-INST-../../models/Bielik-11B-v2.2-Instruct-q4-5 {'confidence': 0.0, 'above': 0, 'below': 100}\n",
      "morfologik_index-sdadas/mmlw-retrieval-roberta-large-Cosine-ipipan-polqa-1000-0.75-INST-../../models/Mistral-7B-Instruct-v0.2-q4-5 {'confidence': 0.0, 'above': 0, 'below': 100}\n",
      "basic_index-ipipan-polqa-500-QA-radlab/polish-qa-v2-1 {'em': 0.21, 'f1': 0.31923809523809527}\n",
      "basic_index-ipipan-polqa-500-QA-timpal0l/mdeberta-v3-base-squad2-1 {'em': 0.16, 'f1': 0.2948095238095238}\n",
      "basic_index-ipipan-polqa-500-INST-../../models/Bielik-11B-v2.2-Instruct-q4-1 {'confidence': 0.0, 'above': 0, 'below': 100}\n",
      "basic_index-ipipan-polqa-500-INST-../../models/Mistral-7B-Instruct-v0.2-q4-1 {'confidence': 0.0, 'above': 0, 'below': 100}\n",
      "basic_index-ipipan-polqa-500-QA-radlab/polish-qa-v2-5 {'em': 0.22, 'f1': 0.3437765567765567}\n",
      "basic_index-ipipan-polqa-500-QA-timpal0l/mdeberta-v3-base-squad2-5 {'em': 0.2, 'f1': 0.3332943722943723}\n",
      "basic_index-ipipan-polqa-500-INST-../../models/Bielik-11B-v2.2-Instruct-q4-5 {'confidence': 0.0, 'above': 0, 'below': 100}\n",
      "basic_index-ipipan-polqa-500-INST-../../models/Mistral-7B-Instruct-v0.2-q4-5 {'confidence': 0.0, 'above': 0, 'below': 100}\n",
      "text-embedding-3-large-Euclid-ipipan-polqa-2000-QA-gpt-4o-mini-1 {'confidence': 0.0, 'above': 0, 'below': 100}\n",
      "text-embedding-3-large-Euclid-ipipan-polqa-2000-QA-gpt-4o-mini-5 {'confidence': 0.0, 'above': 0, 'below': 100}\n",
      "text-embedding-3-large-Cosine-ipipan-polqa-500-QA-gpt-4o-mini-1 {'confidence': 0.0, 'above': 0, 'below': 100}\n",
      "text-embedding-3-large-Cosine-ipipan-polqa-500-QA-gpt-4o-mini-5 {'confidence': 0.0, 'above': 0, 'below': 100}\n"
     ]
    }
   ],
   "source": [
    "# save_scores_to_csv(poquad_scores, \"../../output/generator_poquad_scores.csv\")\n",
    "save_scores_to_csv(polqa_scores, \"../../output/generator_polqa_scores.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
